# UPAD-Toolkit
This is repository for the Underwater Passive Acoustic Data Toolkit


## Please cite following manuscripts if you decide to use toolkit
Beckler, B., Pfau, A., Orescanin, M., Atchley, S., Villemez, N., Joseph, J.E., Miller, C.W. and Margolina, T., 2022. Multilabel classification of heterogeneous underwater soundscapes with Bayesian deep learning. IEEE Journal of Oceanic Engineering, 47(4), pp.1143-1154.

Fischer, J., Orescanin, M., Leary, P. and Smith, K.B., 2023. Active Bayesian deep learning with vector sensor for passive sonar sensing of the ocean. IEEE Journal of Oceanic Engineering, 48(3), pp.837-852.

## Project Goal
Project to generate ship-acoustic machine-learning training, validation and test datasets based on an AIS-track repository of vessel traffic in the Monterey Bay. Evaluation results in the test dataset should
provide a clear indication of training skill, rather than the false impression of skill as is sometimes encountered when the test set is contaminated with nearly identical training set observations.

## Overview
Currently, dataset generation is broken into 2 phases. The first phase analyzes the AIS-track repository and extracts time intervals of interest based on user-provided criteria. The raw time-series audio
for only these time intervals is then fetched from the audio repository. These intervals are broken into smaller segments of user-specified length. Each segment is labeled appropriatly using the
AIS-provided meta-data. Each segment of raw time-series audio and its respective label information is persisted as a tensorflow record to disk.
The second phase consists of splitting and balancing the above-generated repository of tensorflow records into training, validation, and test sets.
The motivation for breaking the above-outlined process into two phases is that, relatively-speaking, the first phase is a time-consuming process that should be executed infrequently. You would not want to
include the first phase as part of a model-building pipeline that does a hyper-parameter search. On the other hand, the second phase is relatively fast. Although phase two is currently executed stand-alone,
you could reasonably integrate it into a model-building pipeline and hyper-parameter search over various splitting and balancing schemes.

## Phase 1 Details
The first phase is executed by running sbatch jobs/tfrecord_gen.sh in the top-level repository directory. This shell script will invoke the main python program, which is called tfrecord_gen.py. This
program expects a number of arguments from the user. For example, the user can specify the --start time and --end time
arguments, which specify the time period of interest. The program will only fetch AIS-track information that falls within this time period. Also, no warning will be provided if the user-specified time period
falls outside data range AIS-track repository.
A note on timezones:


--start and --end arguments are UTC timezone in format YYYYMMDD HHMMSS
.mat filenames (i.e. 180406.mat) are in UTC timezone
AIS datenumber fields in .mat files are in proleptic Gregorian ordinal format in UTC timezone
.wav filenames (m209_oxyz_20190123005827.wav) are in UTC timezone
The above EXTERNAL (they come from outside of the main program) times are converted to nanoseconds since the epoch upon ingestion into the main program.
All INTERNAL times are nanoseconds since the epoch.

Given the --start and --end times, the program fetches the appropriate AIS-track data from AIS repository specified by the --ais_data argument. There is a known AIS repository located in
/smallwork/beards/CS4321/acoustic_datasets/ais_052018_082021, but this is a copy of the master repository that is maintained in an NPS Box folder.
Next, the program ingests a CSV table from disk. The first column consists of a set of unique MMSIs. The other columns are the dead weight tonnage (DWT), vessel size (SIZE), and vessel designation (DESIG).
This table serves as a source of additional information about the vessel with a given MMSI, which are not present in AIS messages and is used to derive the appropriate label for the vessel. The information in
this table was web-scraped from VesselFinder.com. The table was generated by a separate process not discussed here. It should be regenerated when an AIS repository outside the range MAY2018 - AUG2021 is
utilized. The --mmsi_meta_cache argument specifies the location of this CSV file. There is an existing CSV file that has been verified that is located here:
/data/kraken/MBAY_AIS_AUDIO/mmsi_meta_2019_2021.csv.
Next, each trip that each MMSI takes within the detection zone and buffer zone are computed. The radius (km) of the detection zone is specified by the --detect_range argument. The buffer zone radius is hard-coded
as detection range + 10 km. This project has assumed that any vessel outside of the buffer zone can safely be ignored. The trips method of the ais.py file contains the logic for determining
the trips that a vessel takes within the detection zone and buffer zone. The output of this method are 2 tables. One table is for the detection zone trips and the other table is for the buffer
zone trips. Each row of a table consists of a trip, which a trip is defined as an MMSI, zone enter time, zone exit time, vessel designation, vessel cpa to sensor during trip, cpa time, and
a collection of the AIS messages for the trip, which an individual AIS message consists of the message time, latitude, longitude, bearing, range, and speed over ground. Note that a table can
have multiple rows with the same MMSI because it is possible for a ship to transit in and out of a given zone more than once over the period in question.
Next, the program computes the time intervals of relevance. The time intervals of relevance depend on the machine learning problem being attempted, in part. For example, for the
single-ship, multi-class classification problem, the program computes the time periods where there is a single ship in the detection zone and no ships in the buffer zone. Also, for each time
period, the program assigns the appropriate label. The output of this step (compute_intervals) is a dictionary, where the key is a tuple (start_nanos, end_nanos) and the value is the label,
mmsi, and track data. Random time intervals where no ships are present are also selected in this step.
Finally, the raw time-series audio for the above-computed time intervals is fetched in 30-second segments. This is accomplished by first instantiating an AudioFetcher object (see
audio_fetch.py). The AudioFetch constructor takes the above-computed time intervals, the location of the .wav file audio repository (--wav_dir), the filename schema for the .wav files
(--wav_fmt), the rate to sample the audio file (--sample_rate), and whether the audio should be sampled in mono (--mono). Once the AudioFetcher is instantiated, the next 30-second segment
can be fetched by calling the next_segment() method on the AudioFetcher object. The AudioFetcher object will return None when there are no segments remaining. The program fetches every
30-second segment in this manner and writes the raw audio, along with its appropriate meta-data information as tensorflow records to the output directory specified by the --tfrecord_dir
argument.

Phase 2 Details
The above-generated set of tensorflow records can be organized into training, validation, and test splits by executing sbatch jobs/split.sh. This script will invoke the main program in
split.py. Specify the location of the tensorflow records with the --data_dir argument, and the location of the files that contain the composition of each split with the --split_dir
argument. The user can also specify some criteria for balancing and splitting the dataset. The --split_criteria argument defines indivisible unit. For example, if mmsi for this argument
value, then all tfrecords with the same mmsi must reside in the same split. If mmis,month is specified for this argument, then all tfrecords with the same mmsi occurring in the same month
must reside in the same split, but tfrecords with the same mmsi in different months can span different splits. If random is specified then each record is considered unique. The possible
balancing schemes specified by the balance_scheme argument include none and clipE. No balancing is performed if none is specified. If clipE is specified, then the number of Class E
observations are clipped to match the next largest class.

## Conda Environment
See mbayarr.yml for a description of the conda environment that was used to execute the code in this project.

## Slurm Outputs
Before running any jobs, ensure that you have an "output" directory. Most jobs will store the output into this directory for organization purposes
